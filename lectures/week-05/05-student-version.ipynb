{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891ad0db-af6a-4311-8f98-865c5197682a",
   "metadata": {},
   "source": [
    "# Lecture 5 - Student Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d46922-ee6e-4a8c-bddf-8a0b893a9ffe",
   "metadata": {},
   "source": [
    "We first load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad19540-3541-4151-9bf4-f1987ed2048e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, auc\n",
    "from sklearn.utils import resample\n",
    "\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd61b5d-f273-4616-aa44-c0874a579baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the aggregated student data frame.\n",
    "# This data is from an EPFL Linear Algebra flipped classroom. df_lq is aggregated features for the last week of student performance.\n",
    "# ts represents the students' time series features.\n",
    "\n",
    "df_lq = pd.read_csv('{}/aggregated_extended_fc.csv'.format(DATA_DIR))\n",
    "ts = pd.read_csv('{}/time_series_extended_fc.csv'.format(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72168118-0033-47c4-ae99-2ba3b6891267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inactive_students(df, ts):\n",
    "    \"\"\"\n",
    "    Filter the students (removing the ones that are inactive) to proceed with analysis on students who have participated during the entire class.\n",
    "    Inputs: df, ts\n",
    "    Outputs: filtered df, ts\n",
    "    \"\"\"\n",
    "    # Fill all NaNs with strings to make them easier to process\n",
    "    df = df.fillna('NaN')\n",
    "    \n",
    "    # Find all users weeks with 0 clicks on weekends and 0 clicks on weekdays during the first weeks of the semester\n",
    "    df_first = ts[ts.week < 5]\n",
    "    rows = np.where(np.logical_and(df_first.ch_total_clicks_weekend==0, df_first.ch_total_clicks_weekday==0).to_numpy())[0]\n",
    "    df_zero = df_first.iloc[rows, :]\n",
    "    dropusers = np.unique(df_zero.user)\n",
    "\n",
    "    # Drop users with no activity\n",
    "    ts = ts[~ts.user.isin(dropusers)]\n",
    "    df = df[~df.user.isin(dropusers)]\n",
    "    return df, ts\n",
    "\n",
    "df_lq, ts = remove_inactive_students(df_lq, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b2539-bcfc-40df-83d1-9eff25270fec",
   "metadata": {},
   "source": [
    "The `compute_scores` function computes the performance of classifiers with accuracy + AUC. We will use this evaluation function for all our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b78680-efbe-4a07-9213-7c8522698a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(clf, X_train, y_train, X_test, y_test, roundnum=3, report=False):\n",
    "    \"\"\"\n",
    "    Train clf (binary classification) model on X_train and y_train, predict on X_test. Evaluate predictions against ground truth y_test.\n",
    "    Inputs: clf, training set (X_train, y_train), test set (X_test, y_test)\n",
    "    Inputs (optional): roundnum (number of digits for rounding metrics), report (print scores)\n",
    "    Outputs: accuracy, AUC\n",
    "    \"\"\"\n",
    "    # Fit the clf predictor (passed in as an argument)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate roc AUC score\n",
    "    AUC = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    # Print classification results\n",
    "    if report:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return round(accuracy, roundnum), round(AUC, roundnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ca4d9-f07f-4246-bb78-ad1fb3835d51",
   "metadata": {},
   "source": [
    "We compute the pass/fail label of the students in the dataframe to use for the experiments. We will use the aggregated dataframe (df_lq) for all our experiments. If students have a grade higher than or equal to 4, they have passed the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593c81c9-5d4d-4ddc-8b9b-6b3def76169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lq['passed'] = (df_lq.grade >= 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd443ce2-e939-40fe-8870-1c4f87108265",
   "metadata": {},
   "source": [
    "We are interested in model selection and assessment. We will use a random forest model for all our evaluations. For our evaluations, we will investigate behavioral features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de2d363-8d4f-4719-ae67-dfff6dd95f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch_num_sessions', 'ch_time_in_prob_sum', 'ch_time_in_video_sum', 'ch_ratio_clicks_weekend_day', 'ch_total_clicks_weekend', 'ch_total_clicks_weekday', 'ch_time_sessions_mean', 'ch_time_sessions_std', 'bo_delay_lecture', 'bo_reg_peak_dayhour', 'bo_reg_periodicity_m1', 'ma_competency_strength', 'ma_competency_anti', 'ma_content_anti', 'ma_student_shape', 'ma_student_speed', 'mu_speed_playback_mean', 'mu_frequency_action_relative_video_pause', 'wa_num_subs', 'wa_num_subs_correct', 'wa_num_subs_avg', 'wa_num_subs_perc_correct', 'la_pause_dur_mean', 'la_seek_len_std', 'la_pause_dur_std', 'la_time_speeding_up_mean', 'la_time_speeding_up_std', 'la_weekly_prop_watched_mean', 'la_weekly_prop_interrupted_mean', 'la_weekly_prop_interrupted_std', 'la_weekly_prop_replayed_mean', 'la_weekly_prop_replayed_std', 'la_frequency_action_video_play']\n"
     ]
    }
   ],
   "source": [
    "# Filter out demographic features\n",
    "features = [x for x in df_lq.columns if x not in ['user', 'week', 'grade', 'gender', 'category', 'year', 'passed']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561753df-2e54-45fe-baac-65c867a00019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep behavioral features in X.\n",
    "X = df_lq[features]\n",
    "\n",
    "# Our binary indicator variable is based on our evaluation criteria: pass/fail.\n",
    "y = df_lq['passed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aab671-cede-4817-a54c-21cbaaafd931",
   "metadata": {},
   "source": [
    "## Your Turn 1: Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc04c79-7cdc-4f81-b361-ef309004c8b3",
   "metadata": {},
   "source": [
    "In a first experiment, we are interested in assessing the generalizability of the trained model on to new data. We use two different methods to do so: a train-test split and a cross validation.\n",
    "Run the two methods and assess their accuracy/AUC:\n",
    "- What can you observe?\n",
    "- Where do the differences come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72257d09",
   "metadata": {},
   "source": [
    "##### Train-Test Split\n",
    "We split the data in a train-test split (stratified by the outcome variable) and obtain the accuracy and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24643627-f9ed-4d43-b6f7-b454e4f28629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train-test split is 80:20 (as shown by the 0.2 test_size argument). \n",
    "# We choose a random_state to replicate the results in the same split every time we run this notebook.\n",
    "# The stratify argument ensures a proportionate number of passes/fails are in the training set and the test set.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b14647-55de-41e7-850e-b708564c7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize a RandomForestClassifier to make our model predictions.\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b3e51-6eae-4e92-b45c-a64903a03aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use our compute_scores function to evaluate the results of our train-test split classifier.\n",
    "\n",
    "accuracy, AUC = compute_scores(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy for train-test setting: {accuracy}')\n",
    "print(f'AUC for train-test setting: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a332370-626f-4c99-a8ef-2d6d0973ed9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Cross Validation\n",
    "We use a 10-fold cross validation to obtain accuracy and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41970544-d7c1-4008-b5e7-02de9a625683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new Random Forest predictor for our cross-validation comparison.\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43f55e37-caab-4d85-80d8-b93868f04fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with cross-validation: 0.679\n",
      "Mean AUC with cross-validation: 0.680\n"
     ]
    }
   ],
   "source": [
    "# With the cross_validate function, the SciKit Learn library automatically uses stratification across folds with the \"cv\" argument. \n",
    "# In the background, it's using the StratifiedKFold function with 10 folds.\n",
    "# We pass in our desired metrics (\"accuracy\", \"roc_auc\") for evaluation in the \"scoring\" argument.\n",
    "\n",
    "scores = cross_validate(clf, X, y, cv=10, scoring=['accuracy', 'roc_auc'])\n",
    "\n",
    "print(f'Mean accuracy with cross-validation: {scores[\"test_accuracy\"].mean():.3f}')\n",
    "print(f'Mean AUC with cross-validation: {scores[\"test_roc_auc\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64008dc2",
   "metadata": {},
   "source": [
    "### Your solution 1\n",
    "Write your answers in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lecture-05',\n",
    "    'session_owner': 'mlbd-2022',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}\n",
    "\n",
    "# YOUR TURN: what differences can you observe in the metrics (accuracy, AUC) between train-test and cross validation? Where do these differences come from?\n",
    "\n",
    "### Share the answer with us\n",
    "cv_tts = \"\"\n",
    "send(cv_tts, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff442a7-9bf9-4714-b56b-f35a2caaa43e",
   "metadata": {},
   "source": [
    "## Your Turn 2: Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83684f1-1beb-433e-8d1b-6763add6864d",
   "metadata": {},
   "source": [
    "Of course, when training ML models, we want to tune their hyperparameters in order to optimize the performance. In order to tune the hyperparameters of a model, we need to do further splits of our data set. To do so, we can freely combine the approaches presented in the model assessment section. In the following, we present three examples. One of these examples follows an incorrect procedure. Your tasks:\n",
    "- Identify the incorrect example and let us know why it is incorrect\n",
    "- Fix the example such that a correct evaluation procedure is used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab3ad2-2260-4747-9353-0021799fb1d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Example 1 - Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e09002f-ece0-4650-a45c-6b4a2597a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the test set as 20% of the initial data set\n",
    "X_1, X_test, y_1, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0820cd-3a3b-4ed6-80c0-5530ff822987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training set as 70% of the initial dataset\n",
    "# Select the validation set at 10% of the initial dataset (we use 1/8 here because we've already split the set once)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_1, y_1, test_size=1/8, random_state=42, stratify=y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef3c29d-9a52-4816-b741-aa5b7fec8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': np.arange(3, 9),\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "}\n",
    "\n",
    "params_grid = ParameterGrid(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee91665-24ad-4df2-bd93-adf0c41672f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each combination of candidate parameters, fit a classifier on the training set and evaluate it on the validation set\n",
    "results = [[params, compute_scores(RandomForestClassifier(random_state=42, **params), \n",
    "                                   X_train, y_train, X_val, y_val)] for params in params_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddc06c98-b7a5-4e93-b55c-060f9fd5eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort candidate parameters according to their accuracy\n",
    "results = sorted(results, key=lambda x: x[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d6fb0dc-5842-47b5-87a4-3c88bcca9fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the best parameters\n",
    "best_params = results[0][0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9886672f-c4f0-41b4-ac89-199e5710d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-validation-test setting: 0.681\n",
      "AUC for train-validation-test setting: 0.739\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model based on the best parameter settings\n",
    "clf = RandomForestClassifier(random_state=42, **best_params)\n",
    "accuracy, AUC = compute_scores(clf, X_1, y_1, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy for train-validation-test setting: {accuracy}')\n",
    "print(f'AUC for train-validation-test setting: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668a291-549e-43cc-b20b-27949bb60a4f",
   "metadata": {},
   "source": [
    "##### Example 2: 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26bac26d-2e7c-4e74-9a65-ff6b082a15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': np.arange(3, 7),\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4798f07b-a316-46a0-adb3-5adfd38ae4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': array([3, 4, 5, 6]),\n",
       "                         'min_samples_leaf': [1], 'min_samples_split': [2],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             refit='accuracy', scoring=['accuracy', 'roc_auc'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation to identify the best hyperparameters, selecting the ones with the highest accuracy\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=10, scoring=['accuracy', 'roc_auc'], refit='accuracy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "738d0830-b75e-4fe8-a47e-e002686e45a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b33fe1b-46ca-4cd7-8257-0e34a2146266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-validation-test setting: 0.726\n",
      "AUC for train-validation-test setting: 0.707\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.cv_results_['mean_test_accuracy'][clf.best_index_]\n",
    "AUC = clf.cv_results_['mean_test_roc_auc'][clf.best_index_]\n",
    "\n",
    "print(f'Accuracy for train-validation-test setting: {accuracy:.3f}')\n",
    "print(f'AUC for train-validation-test setting: {AUC:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b2dbb-7c7b-47e2-9c1c-a2b075ee7a89",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Example 3: Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e50edcc4-4adc-47d9-be30-1a329ca5d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': np.arange(3, 7),\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2711b789-f195-42f5-b83f-4d550b522faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_size = len(df_lq)\n",
    "B = 100\n",
    "\n",
    "# Generate B samples with replacement\n",
    "samples = [resample(X, y, replace=True, n_samples=df_size) for b in range(B)]\n",
    "# Train a random forest classifier for each sample, cross-validating to find the best parameters\n",
    "clfs = [GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=5).fit(X_b, y_b) for X_b, y_b in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc6ce94f-f28f-4bfb-9683-0ea24f4236d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions for each bootstrap sample (b in range(B)).\n",
    "# Compare predictions against the ground truth (y.loc[[user]]). \n",
    "# Take the mean of predictions for each student (over on the number of times they were predicted).\n",
    "# Takes ~2 mins\n",
    "accuracies_bootstrap = [np.mean([clfs[b].predict(X.loc[[user]]) == y.loc[[user]] for b in range(B) if user not in samples[b][0].index])\n",
    "                        for user in df_lq.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a716579-8793-48ec-977c-7c5a168baac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6705316282894325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the mean of predictions across all students.\n",
    "bootstrap_err = np.mean(accuracies_bootstrap)\n",
    "bootstrap_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b8b235a-4eff-43f9-a2c4-6d205a92e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758119658119658"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a grid-search with 10-fold cross validation\n",
    "training_err_bootstrap = [clfs[b].score(samples[b][0], samples[b][1]) for b in range(B)]\n",
    "training_err = np.mean(training_err_bootstrap)\n",
    "training_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bff35009-9d3c-46a0-8f0e-efcfa34ad21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with .632 leave-one-out bootstrapping: 0.783\n"
     ]
    }
   ],
   "source": [
    "accuracy_632 = 0.632 * bootstrap_err + 0.368 * training_err\n",
    "print(f'Mean accuracy with .632 leave-one-out bootstrapping: {accuracy_632:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e2221",
   "metadata": {},
   "source": [
    "### Your Solution 2\n",
    "Tell us which of the examples above (1, 2, or 3) is incorrect and why.\n",
    "Fix the incorrect example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69994d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN: Which one of the examples above is incorrect, and why?\n",
    "\n",
    "### Share the answer with us\n",
    "model_assessment = \"\"\n",
    "send(model_assessment, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ac502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN: Fix the code for the incorrect example\n",
    "\n",
    "### Share the accuracy and AUC that you obtain with the fixed example with us\n",
    "accuracy = \"\"\n",
    "send(accuracy, 3) \n",
    "\n",
    "auc = \"\"\n",
    "send(auc, 4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
